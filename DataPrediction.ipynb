{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('FinalDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Declaration Type                     0\n",
       "State                                0\n",
       "Disaster Type                        0\n",
       "Disaster Title                       0\n",
       "Start Date                           0\n",
       "End Date                             0\n",
       "Individual Assistance Program        0\n",
       "Individuals & Households Program     0\n",
       "Public Assistance Program            0\n",
       "Hazard Mitigation Program            0\n",
       "Year                                 0\n",
       "State Population                    66\n",
       "Land Area                           66\n",
       "Total Area                          66\n",
       "Animals                             66\n",
       "Arts, Culture, Humanities           66\n",
       "Community Development               66\n",
       "Education                           66\n",
       "Environment                         66\n",
       "Health                              66\n",
       "Human Services                      66\n",
       "Human and Civil Rights              66\n",
       "International                       66\n",
       "Religion                            66\n",
       "Research and Public Policy          66\n",
       "Total Nonprofits                    66\n",
       "No. of Days                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with Null values\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y variable\n",
    "X = data.loc[:, ['Disaster Type', 'Individual Assistance Program', 'Individuals & Households Program', 'Public Assistance Program',\n",
    "                'Hazard Mitigation Program', 'State Population', 'Total Area', 'Animals', 'Education', 'Environment', 'Health',\n",
    "                'Human Services', 'Human and Civil Rights', 'International', 'Religion', 'Research and Public Policy', \n",
    "                 'Total Nonprofits']]\n",
    "\n",
    "y = data.loc[:, ['No. of Days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data into numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.dtypes[X_train.dtypes == 'object'].index.tolist()\n",
    "num_feats = X_train.dtypes[~X_train.dtypes.index.isin(cat_feats)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use own function in Pipeline - to transform numerical and categorical columns\n",
    "def numFeat(data):\n",
    "    return data[num_feats]\n",
    "\n",
    "def catFeat(data):\n",
    "    return data[cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start two separate pipelines for each type of features\n",
    "keep_num = FunctionTransformer(numFeat)\n",
    "keep_cat = FunctionTransformer(catFeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dense function - to apply after one hot encoding\n",
    "class ToDenseTransformer():\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features pipeline\n",
    "pipeline_cat = Pipeline([\n",
    "    ('categorical_features', keep_cat),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense',ToDenseTransformer())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features pipeline\n",
    "pipeline_num = Pipeline([\n",
    "    ('numerical_features', keep_num),\n",
    "    ('scaling', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine both pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine pipelines by creating a feature union\n",
    "feature_union = FeatureUnion([('num_variables', pipeline_num), \n",
    "                              ('cat_variables', pipeline_cat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create main pipeline\n",
    "pipeline = Pipeline(steps=[('features', feature_union),\n",
    "                           ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('num_variables',\n",
       "                                                 Pipeline(steps=[('numerical_features',\n",
       "                                                                  FunctionTransformer(func=<function numFeat at 0x7f006241c0d0>)),\n",
       "                                                                 ('scaling',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('cat_variables',\n",
       "                                                 Pipeline(steps=[('categorical_features',\n",
       "                                                                  FunctionTransformer(func=<function catFeat at 0x7f006241c160>)),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                 ('to_dense',\n",
       "                                                                  <__main__.ToDenseTransformer object at 0x7f006240c820>)]))])),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model create through pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Storm', 'Snow', 'Hurricane', 'Flood', 'Winter', 'Fire', 'Tornado',\n",
       "       'Ice', 'Earthquake', 'Other', 'Terrorism', 'Dam/Levee Break',\n",
       "       'Chemical', 'Tsunami', 'Mud/Landslide'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Disaster Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Storm', 'Hurricane', 'Fire', 'Flood', 'Earthquake', 'Ice', 'Snow',\n",
       "       'Tornado', 'Other', 'Winter', 'Mud/Landslide', 'Volcano',\n",
       "       'Chemical', 'Tsunami'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Disaster Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the data \n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23144355606305045"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction score\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23144355606305045\n",
      "Mean Absolute Error: 19.68571295805295\n",
      "Mean Squared Error: 1042.9178012723435\n",
      "Root Mean Squared Error: 32.29423789582816\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with RandomForestRegresser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize regressor\n",
    "clf = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create main pipeline for RandomForestRegressor\n",
    "pipeline_clf = Pipeline(steps=[('features', feature_union),\n",
    "                           ('regressor', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hafsa/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('num_variables',\n",
       "                                                 Pipeline(steps=[('numerical_features',\n",
       "                                                                  FunctionTransformer(func=<function numFeat at 0x7f006241c0d0>)),\n",
       "                                                                 ('scaling',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('cat_variables',\n",
       "                                                 Pipeline(steps=[('categorical_features',\n",
       "                                                                  FunctionTransformer(func=<function catFeat at 0x7f006241c160>)),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                 ('to_dense',\n",
       "                                                                  <__main__.ToDenseTransformer object at 0x7f006240c820>)]))])),\n",
       "                ('regressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the RandomForestRegressor through pipeline\n",
    "pipeline_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the data with RandomForestRegressor\n",
    "y_pred_clf = pipeline_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705375285641054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction score with RandomForestRegressor\n",
    "pipeline_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7705375285641054\n",
      "Mean Absolute Error: 8.723727145164979\n",
      "Mean Squared Error: 311.37660489653445\n",
      "Root Mean Squared Error: 17.64586651022087\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred_clf))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_clf))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_clf))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'regressor__n_estimators': [200, 500],\n",
    "    'regressor__max_depth' : [4,5,6,7,8]}\n",
    "\n",
    "#{'regressor_min_samples_split': range(2, 403, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(pipeline_clf,\n",
    "                  param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ravel target variable\n",
    "# y_train = np.array(y_train)\n",
    "#y_train = y_train.ravel()\n",
    "#y_test = np.array(y_test)\n",
    "#y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('num_variables',\n",
       "                                                                        Pipeline(steps=[('numerical_features',\n",
       "                                                                                         FunctionTransformer(func=<function numFeat at 0x7f006241c0d0>)),\n",
       "                                                                                        ('scaling',\n",
       "                                                                                         StandardScaler())])),\n",
       "                                                                       ('cat_variables',\n",
       "                                                                        Pipeline(steps=[('categorical_features',\n",
       "                                                                                         FunctionTransformer(func=<function catFeat at 0x7f006241c160>)),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                                        ('to_dense',\n",
       "                                                                                         <__main__.ToDenseTransformer object at 0x7f006240c820>)]))])),\n",
       "                                       ('regressor', RandomForestRegressor())]),\n",
       "             param_grid={'regressor__max_depth': [4, 5, 6, 7, 8],\n",
       "                         'regressor__n_estimators': [200, 500]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the data with GridSearch\n",
    "y_pred_grid = grid_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023593879727535"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7023593879727535\n",
      "Mean Absolute Error: 12.32645099648816\n",
      "Mean Squared Error: 403.8931624523288\n",
      "Root Mean Squared Error: 20.09709338318178\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred_grid))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_grid))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_grid))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor without nonprofit information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y variable\n",
    "X1 = data.loc[:, ['Disaster Type', 'Individual Assistance Program', 'Individuals & Households Program', 'Public Assistance Program',\n",
    "                'Hazard Mitigation Program', 'State Population', 'Total Area']]\n",
    "\n",
    "y1 = data.loc[:, ['No. of Days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into numerical and categorical features\n",
    "cat_feats1 = X_train1.dtypes[X_train1.dtypes == 'object'].index.tolist()\n",
    "num_feats1 = X_train1.dtypes[~X_train1.dtypes.index.isin(cat_feats)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use own function in Pipeline - to transform numerical and categorical columns\n",
    "def numFeat1(data):\n",
    "    return data[num_feats1]\n",
    "\n",
    "def catFeat1(data):\n",
    "    return data[cat_feats1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start two separate pipelines for each type of features\n",
    "keep_num1 = FunctionTransformer(numFeat1)\n",
    "keep_cat1 = FunctionTransformer(catFeat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features pipeline\n",
    "pipeline_cat1 = Pipeline([\n",
    "    ('categorical_features', keep_cat1),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('to_dense',ToDenseTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features pipeline\n",
    "pipeline_num1 = Pipeline([\n",
    "    ('numerical_features', keep_num1),\n",
    "    ('scaling', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine pipelines by creating a feature union\n",
    "feature_union1 = FeatureUnion([('num_variables', pipeline_num1), \n",
    "                              ('cat_variables', pipeline_cat1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create main pipeline\n",
    "# create main pipeline for RandomForestRegressor\n",
    "pipeline_clf1 = Pipeline(steps=[('features', feature_union1),\n",
    "                           ('regressor', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('num_variables',\n",
       "                                                 Pipeline(steps=[('numerical_features',\n",
       "                                                                  FunctionTransformer(func=<function numFeat1 at 0x7f005e034dc0>)),\n",
       "                                                                 ('scaling',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('cat_variables',\n",
       "                                                 Pipeline(steps=[('categorical_features',\n",
       "                                                                  FunctionTransformer(func=<function catFeat1 at 0x7f005e0349d0>)),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore')),\n",
       "                                                                 ('to_dense',\n",
       "                                                                  <__main__.ToDenseTransformer object at 0x7f005dfe08e0>)]))])),\n",
       "                ('regressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the RandomForestRegressor through pipeline\n",
    "pipeline_clf1.fit(X_train1, y_train1.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the data with RandomForestRegressor\n",
    "y_pred_clf1 = pipeline_clf1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7774515172045482"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction score with RandomForestRegressor\n",
    "pipeline_clf1.score(X_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774515172045482\n",
      "Mean Absolute Error: 8.724613964166862\n",
      "Mean Squared Error: 301.74015517604244\n",
      "Root Mean Squared Error: 17.370669393435662\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test1, y_pred_clf1))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test1, y_pred_clf1))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test1, y_pred_clf1))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test1, y_pred_clf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Disaster Type', 'Individual Assistance Program',\n",
       "       'Individuals & Households Program', 'Public Assistance Program',\n",
       "       'Hazard Mitigation Program', 'State Population', 'Total Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
